{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Querying Retriever \n",
    "\n",
    "- First, get the matching, and then do the semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content filtered with Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-None-tERZuTrLcEkHgNg0QE2KT3BlbkFJlKUWhBVVDW5qQBpMk58L\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document # langchain Document Schema\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# Embeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "\n",
    "from langchain.vectorstores import Chroma # vector store\n",
    "\n",
    "# embeddings = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerlshin/ENV/env_torch/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "/home/jerlshin/ENV/env_torch/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHubEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpointEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"EleutherAI/gpt-neo-2.7B\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.7, \n",
    "        \"max_length\": 100\n",
    "    }\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceHubEmbeddings(\n",
    "    repo_id=\"sentence-transformers/all-MiniLM-L6-v2\",  # Use other models like 'sentence-transformers/paraphrase-MiniLM-L6-v2' if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerlshin/ENV/env_torch/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: What is artificial intelligence?\n",
      "\n",
      "Artificial intelligence (AI) is the scientific discipline that studies and implements the scientific theory of how computers can be programmed to perform tasks that are traditionally human tasks.\n",
      "\n",
      "Artificial intelligence in the sense of AI is central to the development of the internet of things.\n",
      "\n",
      "AI is a relatively new field of study, which was first formulated in the 1950s by the so-called \"fathers of AI\", John McCarthy and John McCarthy Jr. The field was further developed by Jerome McCarthy\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is artificial intelligence?\"\n",
    "response = llm(prompt)\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Vector: [-0.004465974401682615, -0.06313367933034897, 0.06713636964559555, 6.859412678750232e-05, -0.011738572269678116, -0.03995257988572121, -0.002753122942522168, -0.010048198513686657, 0.025715341791510582, 0.01568259671330452]\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Artificial intelligence is fascinating.\"\n",
    "embedding_vector = embeddings.embed_query(sample_text)\n",
    "print(\"Embedding Vector:\", embedding_vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "\n",
    "    # schema from the langchain for Document \n",
    "    # Page content and Metadata\n",
    "    Document(\n",
    "        page_content=\"Complex, layered, rich red with dark fruit flavors\",\n",
    "        metadata={\"name\":\"Opus One\", \"year\": 2018, \"rating\": 96, \"grape\": \"Cabernet Sauvignon\", \"color\":\"red\", \"country\":\"USA\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Luxurious, sweet wine with flavors of honey, apricot, and peach\",\n",
    "        metadata={\"name\":\"Château d'Yquem\", \"year\": 2015, \"rating\": 98, \"grape\": \"Sémillon\", \"color\":\"white\", \"country\":\"France\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Full-bodied red with notes of black fruit and spice\",\n",
    "        metadata={\"name\":\"Penfolds Grange\", \"year\": 2017, \"rating\": 97, \"grape\": \"Shiraz\", \"color\":\"red\", \"country\":\"Australia\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Elegant, balanced red with herbal and berry nuances\",\n",
    "        metadata={\"name\":\"Sassicaia\", \"year\": 2016, \"rating\": 95, \"grape\": \"Cabernet Franc\", \"color\":\"red\", \"country\":\"Italy\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Highly sought-after Pinot Noir with red fruit and earthy notes\",\n",
    "        metadata={\"name\":\"Domaine de la Romanée-Conti\", \"year\": 2018, \"rating\": 100, \"grape\": \"Pinot Noir\", \"color\":\"red\", \"country\":\"France\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Crisp white with tropical fruit and citrus flavors\",\n",
    "        metadata={\"name\":\"Cloudy Bay\", \"year\": 2021, \"rating\": 92, \"grape\": \"Sauvignon Blanc\", \"color\":\"white\", \"country\":\"New Zealand\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Rich, complex Champagne with notes of brioche and citrus\",\n",
    "        metadata={\"name\":\"Krug Grande Cuvée\", \"year\": 2010, \"rating\": 93, \"grape\": \"Chardonnay blend\", \"color\":\"sparkling\", \"country\":\"New Zealand\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Intense, dark fruit flavors with hints of chocolate\",\n",
    "        metadata={\"name\":\"Caymus Special Selection\", \"year\": 2018, \"rating\": 96, \"grape\": \"Cabernet Sauvignon\", \"color\":\"red\", \"country\":\"USA\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Exotic, aromatic white with stone fruit and floral notes\",\n",
    "        metadata={\"name\":\"Jermann Vintage Tunina\", \"year\": 2020, \"rating\": 91, \"grape\": \"Sauvignon Blanc blend\", \"color\":\"white\", \"country\":\"Italy\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# create a vector store (chroma) from the documents \n",
    "vectorstore = Chroma.from_documents(docs, embeddings) # send the list of docs and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x73eb77f0fd10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Self-querying retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information about the metadata**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, everything is about the wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# get the retriever from the langchain\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "# To set the information about the attribute\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"grape\",\n",
    "        description=\"The grape used to make the wine\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"name\",\n",
    "        description=\"The name of the wine\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"color\",\n",
    "        description=\"The color of the wine\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    # year is the integer for search\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the wine was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"country\",\n",
    "        description=\"The name of the country the wine comes from\",\n",
    "        type=\"string\",  # just one word\n",
    "    ),\n",
    "    AttributeInfo(  # Rober Parker is the famous wine reviewer\n",
    "        name=\"rating\", description=\"The Robert Parker rating for the wine 0-100\", type=\"integer\" #float\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Brief description of the wine\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the retriever now uses the vectorstore of documents with metadata along with information about the metadata\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever.get_relevant_documents(\"I want a wine that has fruity nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"I want a wine that has fruity nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"I want a wine that has fruity nodes and has a rating above 97\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\n",
    "    \"What wines come from Italy?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\n",
    "    \"What's a wine after 2015 but before 2020 that's all earthy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter K \n",
    "\n",
    "We can also use the self query retriever to specify K \n",
    "The number of documents to fetch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    enable_limit=True,  # filtering top k results\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"what are two that have a rating above 97\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"what are two wines that come from australia or New zealand\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
